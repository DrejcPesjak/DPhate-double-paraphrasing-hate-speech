Hello my name is Drejc Pesjak, and today i will present you my bachelor's thesis Hate speech paraphraser.

In todays day and age, hate speech can be found everywhere on the web, from social media to news sites and forums.
In order to make their platform pleasent to use
these sites try to defend by using moderators, people hired to siff through all the content posted by the users 
and remove those posts which go againts the community guidlines (aka rules created by the owners).
Because of the large amount of comments generated by the users, the moderators utilize the hate speech detection software/algorithms,
which can fastly label the incoming content and pass it back to the moderators for further inspection
But the complete removal of comments goes against the basic human right, the freedom of expression

So we propose a system which turns hateful comments into non hateful ones.
this limits the hate, while still giving freedom to the users to exprees their thoughts and ideas
Such solution would be to benefit everyone involved, (from) the users which cannot be beliteled anymore, 
and haters that can still express themself and make a point,
the moderators which don't have to look at all the ugly, and risk their mental health
and the companies, which can provide a better product, a platform that is enjoable with a degree of freedom 

This is what we strived to achieve in our system DPhate.
in the first two steps we decontract the input sentence, so expand the shortened phrases like isn't to is not and don't to do not.
and then we delete vulgar adjectives and adverbs, which were found to carry less information.
then the system does up to two paraphrasings, the second happens only if the previous steps did not yield succesful results
so if either all generated sentences are toxic, or none of the non-toxic ones is similar enough to the original text
paraphrasing is done by the PEGASUS library, that returns multiple similar sentences, the diversity of which can be controlled by adjusting the parameters of the algorithm (a transformer based architecture)
for hate speech detection we used the Detoxify library that outputs a probability between 0 and 1 (an ALBERT model trained on hate labeled wiki comments)
similiratiy was calculated on BERT embeddings with cosine similarity
this system was tested and then evaluated on the hateful examples of the Hatexplain dataset, a dataset of scraped and labeled twitter comments 

In the evalution process we measured how hateful the generated comment was, a how similar it was to the original sentence.
we did the evaluation in to ways, first was an automatic system, whereas in the second one human evaluators were used to assess the qulity

in the automated system, 
an ensemble method called stacking was used for evaluating hatefulness  
it uses three pre-trained hate speech detectors as a base, 
their predictions where than passed to the meta learner, a logistic regression model, which produced the final score
as for the similarity the model simCSE was used, which is currently the best performing model on two datasets for semantic similarity
With this 69% percent of the generated sentences were labeled as non hateful and 92% percent of the sentence pairs as similar
if we take into consideration that multiple solutions a generated for each input sentence, we got that almost 85% of input sentences got at least one acceptable transformation

in the evalution done by humans
we utilized the crowdsourcing platform microWorkers
where we posted a campaign, to which 61 people from english speaking coutries applied and labeled 876 examples
each one was labeled by 3 different evaluators
when analized, 82% percent of examples were found to be non hateful and 51% percent of them were deemed similar
#again due to the non-greedy paraphrasing   
in conclusion 68% of input sentences got at least one acceptable transformation.

Here are some of the examples deemed acceptable by the humans.

To conclude, we talked about to problem of hate speech on social media and the problem of blantantly censoring it, and how that limits freedom of speech
So we talked about another approach, of removing hate from the hateful comments, this was achieved with our system DPhate 
Which gave good results, 85% or 68% of input sentences were improved
